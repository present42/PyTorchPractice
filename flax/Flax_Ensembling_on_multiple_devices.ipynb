{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOtcx+jg0xJXLa/0kr5og1M"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RBpva1mwyipd"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"XLA_FLAGS\"] = '--xla_force_host_platform_device_count=8'"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Flax provides ..\n",
        " 1. Interface to specify partition of your data when defining `flax.linen.Module`\n",
        " 2. Utility functinos to generate the sharding information that `jax.jit` requires to run.\n",
        " 3. An interface to customize your axis name called \"logical axis annotations\" to decouple both your Module code and partition plan to experiment with different partition layouts more easily."
      ],
      "metadata": {
        "id": "9TTeTic30FGP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import functools\n",
        "from typing import Optional, Callable\n",
        "\n",
        "import numpy as np\n",
        "import jax\n",
        "from jax import lax, random, numpy as jnp\n",
        "\n",
        "import flax\n",
        "from flax import struct, traverse_util, linen as nn\n",
        "from flax.core import freeze, unfreeze\n",
        "from flax.training import train_state, checkpoints\n",
        "\n",
        "import optax"
      ],
      "metadata": {
        "id": "tLTNzzwx0HEv"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"We have 8 fake Jax deivces now: {jax.devices()}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "n0xkSnrEzqVa",
        "outputId": "7c31506b-e313-464d-e76d-b9dca443d730"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "We have 8 fake Jax deivces now: [CpuDevice(id=0), CpuDevice(id=1), CpuDevice(id=2), CpuDevice(id=3), CpuDevice(id=4), CpuDevice(id=5), CpuDevice(id=6), CpuDevice(id=7)]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from jax.sharding import Mesh, PartitionSpec as P, NamedSharding\n",
        "from jax.lax import with_sharding_constraint\n",
        "from jax.experimental import mesh_utils"
      ],
      "metadata": {
        "id": "FIhz7zZ00uKm"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# create a mesh and annotate each axis with a name\n",
        "device_mesh =mesh_utils.create_device_mesh((2, 4))\n",
        "print(device_mesh)\n",
        "\n",
        "# annotate each axis with a name using the axis_names param\n",
        "mesh = Mesh(devices=device_mesh, axis_names=('data', 'model'))\n",
        "print(mesh)\n",
        "\n",
        "def mesh_sharding(pspec: jax.sharding.PartitionSpec) -> NamedSharding:\n",
        "  return NamedSharding(mesh, pspec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VzJMMAog09P-",
        "outputId": "c7b8bd17-fda9-4ae8-b673-045592fdfe34"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[CpuDevice(id=0) CpuDevice(id=1) CpuDevice(id=2) CpuDevice(id=3)]\n",
            " [CpuDevice(id=4) CpuDevice(id=5) CpuDevice(id=6) CpuDevice(id=7)]]\n",
            "Mesh('data': 2, 'model': 4)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Define a layer"
      ],
      "metadata": {
        "id": "V4WiViDJ14Ve"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "To shard the params efficiently, apply the following APIs to annotate the parameters and intermediate variables:\n",
        " 1. Use `flax.linen.with_partitioning` to decorate the initializer function when creating sub-layers or raw parameters.\n",
        " 2. Apply `jax.lax.with_sharding_constraint` to annotate intermediate variables like `y` and `z` to force a particular sharding pattern when the ideal constraint is known."
      ],
      "metadata": {
        "id": "nuaAH5Zp2BVO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class DotReluDot(nn.Module):\n",
        "  depth: int\n",
        "  dense_init: Callable = nn.initializers.xavier_normal()\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "\n",
        "    y = nn.Dense(self.depth,\n",
        "                 kernel_init=nn.with_partitioning(self.dense_init, (None, 'model')),\n",
        "                 use_bias=False, # or overwrite with `bias_init`\n",
        "                 )(x)\n",
        "    y = jax.nn.relu(y)\n",
        "\n",
        "    # Force a local sharding annotation\n",
        "    y = with_sharding_constraint(y, mesh_sharding(P('data', 'model')))\n",
        "\n",
        "    W2 = self.param(\n",
        "        'W2',\n",
        "        nn.with_partitioning(self.dense_init, ('model', None)),\n",
        "        (self.depth, x.shape[-1])\n",
        "    )\n",
        "\n",
        "    z = jnp.dot(y, W2)\n",
        "    # Force a local sharding annotation\n",
        "    z = with_sharding_constraint(z, mesh_sharding(P('data', None)))\n",
        "\n",
        "    # returns a tuple to conform with the API `flax.linen.scan`\n",
        "    # as shown in the cell below\n",
        "    return z, None"
      ],
      "metadata": {
        "id": "v53R2Zcy1sx2"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "- When you define `W1` with shape `(x.shape[-1], self.depth)` and annotate as `(None, 'model')`:\n",
        " - The first dimension is replicated across all devices\n",
        " - The second dimension (of length `self.depth`) will be sharded over the `model` axis of the device mesh.\n",
        "- When you annotate the output `z` as `('data', None)`:\n",
        " - The first dimension will be sharded over the 'data' axis\n",
        " - The second dimension will be replicated across all devices."
      ],
      "metadata": {
        "id": "Yyff79FC5Ij0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Define a model with `flax.linen.scan` lifted transformation"
      ],
      "metadata": {
        "id": "a8yvUyei7wRz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  num_layers: int\n",
        "  depth: int\n",
        "  use_scan: bool\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.use_scan:\n",
        "      x, _ = nn.scan(DotReluDot, length=self.num_layers,\n",
        "                     variable_axes={\"params\": 0},\n",
        "                     split_rngs={\"params\": True},\n",
        "                     metadata_params={nn.PARITION_NAME: None}\n",
        "                     )(self.depth)(x)\n",
        "    else:\n",
        "      for i in range(self.num_layers):\n",
        "        x, _ = DotReluDot(self.depth)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "axP6wAgH5H0R"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ML hyperparameters\n",
        "BATCH, LAYERS, DEPTH, USE_SCAN = 8, 4, 1024, False\n",
        "\n",
        "# create fake inputs\n",
        "x = jnp.ones((BATCH, DEPTH))\n",
        "# initialize a PRNG Key\n",
        "k = random.key(0)\n",
        "\n",
        "# create an optax optimizer\n",
        "optimizer = optax.adam(learning_rate=0.001)\n",
        "# instantiate the model\n",
        "model = MLP(LAYERS, DEPTH, USE_SCAN)"
      ],
      "metadata": {
        "id": "fGfDOlDR93yf"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that device axis names like `data`, `model`, or `None` are passed into both `flax.linen.with_partitioning` and `jax.lax.with_sharding_constraint` API calls"
      ],
      "metadata": {
        "id": "0KplA1aj4bym"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "> `flax.linen.with_partitioning`: Wraps a functionâ€™s return value with `Partitioned`"
      ],
      "metadata": {
        "id": "DDFYaf-t4suD"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Specify sharding\n",
        "\n",
        "### input's sharding"
      ],
      "metadata": {
        "id": "IAEQIHVg-qBl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for data parallelism, you can shard the batched input x across the data axis\n",
        "x_sharding = mesh_sharding(P('data', None))\n",
        "# use jax.device_put to place it onto the correct devices\n",
        "x = jax.device_put(x, x_sharding)\n",
        "jax.debug.visualize_array_sharding(x)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 209
        },
        "id": "m-vyHayK4axf",
        "outputId": "b07822cb-bb6d-4c37-f394-f1066910dcb7"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,1,2,3\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m                                   \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 4,5,6,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m                                   \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                  CPU 0,1,2,3                                   </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                  CPU 4,5,6,7                                   </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Output's sharding\n",
        "You need to compile `model.init()` and its output as a pytree of parameters. Additionally, you may sometimes need to wrap it with a `flax.training.train_data` to track other variables, such as optimizer states and that would make the output an even more complex pytree.\n",
        "\n",
        "To achieve this, luckily, you don't have to hardcode the output's sharding by hand. Instead,\n",
        "1. Evaluate `model.init` abstractly using `jax.eval_shape`\n",
        "2. Use `flax.linen.get_sharding` to automatically generate the `jax.sharding.NamedSharding`.\n",
        " - This step utilizes the `flax.linen.with_partitioning` annotations in the earlier def to generate the correct sharding for the parameters."
      ],
      "metadata": {
        "id": "4t8N7AeR_Ji2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def init_fn(k, x, model, optimizer):\n",
        "  variables = model.init(k, x) # Initialize the model\n",
        "  state = train_state.TrainState.create(\n",
        "      apply_fn=model.apply,\n",
        "      params=variables['params'],\n",
        "      tx=optimizer\n",
        "  )\n",
        "  return state\n"
      ],
      "metadata": {
        "id": "HVFQEZmI_F1R"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "abstract_variables = jax.eval_shape(\n",
        "    functools.partial(init_fn, model=model, optimizer=optimizer),\n",
        "    k,\n",
        "    x\n",
        ")\n",
        "\n",
        "# This `state_sharding` has the same pytree structure as `state`\n",
        "# , which is the output of the `init_fn`\n",
        "state_sharding = nn.get_sharding(abstract_variables, mesh)\n",
        "state_sharding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P3KbgkNqAA-O",
        "outputId": "aaf93975-ca84-4fad-b726-ad270f5a9997"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainState(step=NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec()), apply_fn=<bound method Module.apply of MLP(\n",
              "    # attributes\n",
              "    num_layers = 4\n",
              "    depth = 1024\n",
              "    use_scan = False\n",
              ")>, params={'DotReluDot_0': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_1': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_2': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_3': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}}, tx=GradientTransformationExtraArgs(init=<function chain.<locals>.init_fn at 0x78abaf318550>, update=<function chain.<locals>.update_fn at 0x78abaf318af0>), opt_state=(ScaleByAdamState(count=NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec()), mu={'DotReluDot_0': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_1': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_2': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_3': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}}, nu={'DotReluDot_0': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_1': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_2': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}, 'DotReluDot_3': {'Dense_0': {'kernel': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))}, 'W2': NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec('model', None))}}), EmptyState()))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "jit_init_fn = jax.jit(init_fn, static_argnums=(2, 3),\n",
        "                      in_shardings=(mesh_sharding(()), x_sharding),\n",
        "                      out_shardings=state_sharding)\n",
        "\n",
        "initialized_state = jit_init_fn(k, x, model, optimizer)\n",
        "\n",
        "jax.debug.visualize_array_sharding(initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].value)\n",
        "jax.debug.visualize_array_sharding(initialized_state.params['DotReluDot_0']['W2'].value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 385
        },
        "id": "uOjgrtgKAuXy",
        "outputId": "5516543b-fa17-43c8-a943-e4303a2eb761"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\"> CPU 0,4 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\"> CPU 1,5 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\"> CPU 2,6 </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\"> CPU 3,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         CPU 0,4         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         CPU 1,5         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         CPU 2,6         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         CPU 3,7         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect the Module output"
      ],
      "metadata": {
        "id": "DF3VFQF4C7SB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(initialized_state.params['DotReluDot_0']['Dense_0']['kernel']))\n",
        "print(type(initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].value))\n",
        "print(initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].names)\n",
        "print(initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].value.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7VZN6SvUAXtt",
        "outputId": "66317958-098f-4ef6-f9c9-7d59c480b80d"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'flax.core.meta.Partitioned'>\n",
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "(None, 'model')\n",
            "(1024, 1024)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can accesss the raw `jax.Arrays` by calling `flax.linen.meta.unbox()` upon the dictionary, or call `.value` upon individual variable. You can also use `flax.linen.meta.replace_boxed()` to change the underlying `jax.Array` without modifying the sharding annotations."
      ],
      "metadata": {
        "id": "DaGzZreNDOVG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "unboxed_params = nn.meta.unbox(initialized_state.params)\n",
        "all_zero = jax.tree_map(jnp.zeros_like, unboxed_params)\n",
        "all_zero_params = nn.meta.replace_boxed(initialized_state.params, all_zero)\n",
        "assert jnp.sum(nn.meta.unbox(all_zero_params['DotReluDot_0']['Dense_0']['kernel'])) == 0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tMfO6sZNDCED",
        "outputId": "f66560b5-c6b0-4c2f-a320-bfa0a6838024"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-17-90a2a0210113>:2: DeprecationWarning: jax.tree_map is deprecated: use jax.tree.map (jax v0.4.25 or newer) or jax.tree_util.tree_map (any JAX version).\n",
            "  all_zero = jax.tree_map(jnp.zeros_like, unboxed_params)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can also check the underlying `jax.sharding` of each parameter, which is now more internal than `NamedSharding`."
      ],
      "metadata": {
        "id": "O_FRYiG8EViS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].value.sharding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4Wz4i4fEHqF",
        "outputId": "6fd9a7f5-111b-41c5-828e-8ef9b920197e"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(initialized_state.step)\n",
        "initialized_state.step.sharding"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYyKhw98Ekay",
        "outputId": "57ae1e15-a1d9-4c66-dd31-43d70375495d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec())"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can use `jax.tree.map` to perform mass computation on a dict of boxed params, in the same way as on a dict of JAX arrays"
      ],
      "metadata": {
        "id": "d2aZzir1E2-w"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "diff = jax.tree.map(\n",
        "    lambda a, b: a - b,\n",
        "    initialized_state.params['DotReluDot_0'],\n",
        "    initialized_state.params['DotReluDot_0']\n",
        ")\n",
        "diff_array = diff['Dense_0']['kernel'].value\n",
        "print(type(diff_array))\n",
        "print(diff_array.shape)\n",
        "print(diff_array.sharding)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eujz90tJEuQC",
        "outputId": "1153b8c6-416d-41c5-c48f-19f2a555c090"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "(1024, 1024)\n",
            "NamedSharding(mesh=Mesh('data': 2, 'model': 4), spec=PartitionSpec(None, 'model'))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "@functools.partial(jax.jit, in_shardings=(state_sharding, x_sharding),\n",
        "                   out_shardings=state_sharding)\n",
        "def train_step(state, x):\n",
        "  # a fake loss fcn\n",
        "  def loss_unrolled(params):\n",
        "    y = model.apply({'params': params}, x)\n",
        "    return y.sum()\n",
        "  grad_fn = jax.grad(loss_unrolled)\n",
        "  grads = grad_fn(state.params)\n",
        "  state = state.apply_gradients(grads=grads)\n",
        "  return state\n",
        "\n",
        "with mesh:\n",
        "  new_state = train_step(initialized_state, x)"
      ],
      "metadata": {
        "id": "iagT0oA8FG2Y"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f'Sharding of Weight 1:')\n",
        "jax.debug.visualize_array_sharding(initialized_state.params['DotReluDot_0']['Dense_0']['kernel'].value)\n",
        "print(f'Sharding of Weight 2:')\n",
        "jax.debug.visualize_array_sharding(initialized_state.params['DotReluDot_0']['W2'].value)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "RHY-_0YOGNnd",
        "outputId": "100ea96d-a820-4a57-982b-5d57f3a21fbe"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharding of Weight 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\"> CPU 0,4 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\"> CPU 1,5 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\"> CPU 2,6 </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\"> CPU 3,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sharding of Weight 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         CPU 0,4         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         CPU 1,5         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         CPU 2,6         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         CPU 3,7         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a compiled inference step\n",
        "@functools.partial(jax.jit, in_shardings=(state_sharding, x_sharding),\n",
        "                   out_shardings=x_sharding)\n",
        "def apply_fn(state, x):\n",
        "  return state.apply_fn({'params': state.params}, x)\n",
        "\n",
        "with mesh:\n",
        "  y = apply_fn(new_state, x)\n",
        "\n",
        "print(type(y))\n",
        "print(y.dtype)\n",
        "print(y.shape)\n",
        "jax.debug.visualize_array_sharding(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 265
        },
        "id": "04pin_hbGVW8",
        "outputId": "10301dbc-1de8-49d7-d24f-72fd4f840c3f"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'jaxlib.xla_extension.ArrayImpl'>\n",
            "float32\n",
            "(8, 1024)\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,1,2,3\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m                                   \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                  \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 4,5,6,7\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m                                   \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                                                                                \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                  CPU 0,1,2,3                                   </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                  CPU 4,5,6,7                                   </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                                                                                </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Profiling\n",
        "\n",
        "If you are running on a TPU pod or a pod slice, you can use a custom `block_all` utility function"
      ],
      "metadata": {
        "id": "NSkhCjFIG2Ji"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%%timeit\n",
        "\n",
        "def block_all(xs):\n",
        "  jax.tree.map(lambda x: x.block_until_ready(), xs)\n",
        "  return xs\n",
        "\n",
        "with mesh:\n",
        "  new_state = block_all(train_step(initialized_state, x))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q2dF_6_hGyF9",
        "outputId": "a7e538d9-098c-441f-e416-30a4fe64fa04"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "403 ms Â± 65.2 ms per loop (mean Â± std. dev. of 7 runs, 1 loop each)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Logical axis annotation\n",
        "\n",
        "Jax's automatic SPMD encourages users to explore different sharding layouts to find the optimal one.\n",
        "\n",
        "The `LogicalDotReluDot` and `LogicalMLP` Module def below are similar to the Modules you created earlier, except for the following:\n",
        " 1. All axes are annotated with more concrete, meaningful names.\n",
        " 2. `flax.linen.with_logical_partitioning` replaces `flax.linen.with_partitioning`; and `flax.linen.with_logical_constraint` replaces `jax.with_sharding_constraint`\n",
        "\n"
      ],
      "metadata": {
        "id": "EQFOjCnIHPBx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LogicalDotReluDot(nn.Module):\n",
        "  depth: int\n",
        "  dense_init: Callable = nn.initializers.xavier_normal()\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    y = nn.Dense(self.depth,\n",
        "                 kernel_init=nn.with_logical_partitioning(self.dense_init, ('embed', 'hidden')),\n",
        "                 use_bias=False,\n",
        "                 )(x)\n",
        "    y = jax.nn.relu(y)\n",
        "    # force a local sharding annotation\n",
        "    y = with_sharding_constraint(y, mesh_sharding(P('data', 'model')))\n",
        "\n",
        "    W2 = self.param(\n",
        "        'W2',\n",
        "        nn.with_logical_partitioning(self.dense_init, ('hidden', 'embed')),\n",
        "        (self.depth, x.shape[-1])\n",
        "    )\n",
        "\n",
        "    z = jnp.dot(y, W2)\n",
        "    # Force a local sharding annotation\n",
        "    z = nn.with_logical_constraint(z, ('batch', 'embed'))\n",
        "    return z, None\n",
        "\n",
        "class LogicalMLP(nn.Module):\n",
        "  num_layers: int\n",
        "  depth: int\n",
        "  use_scan: bool\n",
        "\n",
        "  @nn.compact\n",
        "  def __call__(self, x):\n",
        "    if self.use_scan:\n",
        "      x, _ = nn.scan(LogicalDotReluDot, length=self.num_layers,\n",
        "                     variable_axes={\"params\": 0},\n",
        "                     split_rngs={\"params\": True},\n",
        "                     metadata_params={nn.PARITION_NAME: None}\n",
        "                     )(self.depth)(x)\n",
        "    else:\n",
        "      for i in range(self.num_layers):\n",
        "        x, _ = LogicalDotReluDot(self.depth)(x)\n",
        "    return x"
      ],
      "metadata": {
        "id": "VWoakqwFHIJ7"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, initiate a model and try to figure out what sharding its `state` should have.\n",
        "\n",
        "To allow the device mesh to take your model correctly, you need to decide which of these logical axis names are mapped to the devices axis 'data' or 'model'."
      ],
      "metadata": {
        "id": "jSCQgwEnJVGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Unspecified rule means unsharded by default,\n",
        "# so no need to specify ('embed', None),\n",
        "# and ('layer', None)\n",
        "rules = (('batch', 'data'),\n",
        "         ('hidden', 'model'))\n",
        "\n",
        "logical_model = LogicalMLP(LAYERS, DEPTH, USE_SCAN)\n",
        "\n",
        "logical_abstract_variables = jax.eval_shape(\n",
        "    functools.partial(init_fn, model=logical_model, optimizer=optimizer), k, x\n",
        ")\n",
        "logical_state_spec = nn.get_partition_spec(logical_abstract_variables)\n",
        "print('annotations are logical, not mesh-specific: ',\n",
        "      logical_state_spec.params['LogicalDotReluDot_0']['Dense_0']['kernel'])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0SvhT-akJM7G",
        "outputId": "4d6590ef-6d4f-4770-9cb1-7bd36eb63e9c"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "annotations are logical, not mesh-specific:  PartitionSpec('embed', 'hidden')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logical_state_sharding = nn.logical_to_mesh_sharding(logical_state_spec, mesh, rules)\n",
        "print('sharding annotations are mesh-specific: ',\n",
        "      logical_state_sharding.params['LogicalDotReluDot_0']['Dense_0']['kernel'].spec)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kpoW2fqyKOXA",
        "outputId": "eb0f34f5-84fe-478d-e892-dbfda34b82cd"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sharding annotations are mesh-specific:  PartitionSpec(None, 'model')\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "You can verify that the `logical_state_spec` here has the same content as `state_spec` in the previous example. This allows you to `jax.jit` your Module's `flax.linen.Module.init` and `flax.linen.Module.apply` the same way in the above"
      ],
      "metadata": {
        "id": "Jdi5xQyNKxER"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "state_sharding.params['DotReluDot_0'] == logical_state_sharding.params['LogicalDotReluDot_0']"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QwD2qqyvKoPE",
        "outputId": "24426483-df34-431d-fb51-27668387ce92"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "logical_jit_init_fn = jax.jit(init_fn, static_argnums=(2, 3),\n",
        "                              in_shardings=(mesh_sharding(()), x_sharding),\n",
        "                              out_shardings=logical_state_sharding)\n",
        "\n",
        "logical_initialized_state = logical_jit_init_fn(k, x, logical_model, optimizer)"
      ],
      "metadata": {
        "id": "cSHCPY2RLHYr"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"sharding of weight 1:\")\n",
        "jax.debug.visualize_array_sharding(logical_initialized_state.params['LogicalDotReluDot_0']['Dense_0']['kernel'].value)\n",
        "print(f\"sharding of weight 2:\")\n",
        "jax.debug.visualize_array_sharding(logical_initialized_state.params['LogicalDotReluDot_0']['W2'].value)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 422
        },
        "id": "3hd3e1-ILnD7",
        "outputId": "fca92108-8dc4-4e8e-ac0d-bb67e898a26a"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sharding of weight 1:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\"> CPU 0,4 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\"> CPU 1,5 </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\"> CPU 2,6 </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\"> CPU 3,7 </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         </span><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         </span><span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sharding of weight 2:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121mCPU 0,4\u001b[0m\u001b[38;2;255;255;255;48;2;57;59;121m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;57;59;121m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214mCPU 1,5\u001b[0m\u001b[38;2;255;255;255;48;2;222;158;214m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;222;158;214m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74mCPU 2,6\u001b[0m\u001b[38;2;255;255;255;48;2;173;73;74m         \u001b[0m\n",
              "\u001b[38;2;255;255;255;48;2;173;73;74m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107mCPU 3,7\u001b[0m\u001b[38;2;0;0;0;48;2;181;207;107m         \u001b[0m\n",
              "\u001b[38;2;0;0;0;48;2;181;207;107m                         \u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">         CPU 0,4         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #393b79\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">         CPU 1,5         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #de9ed6\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">         CPU 2,6         </span>\n",
              "<span style=\"color: #ffffff; text-decoration-color: #ffffff; background-color: #ad494a\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">         CPU 3,7         </span>\n",
              "<span style=\"color: #000000; text-decoration-color: #000000; background-color: #b5cf6b\">                         </span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "When to use device axis / logical axis\n",
        "- Device mesh axis: If you want a very simple model, or you"
      ],
      "metadata": {
        "id": "vFRBg6sDMAqj"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "t__X_y6zLdga"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}