{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMU7BJPe68pyE1MgF+toNEa"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 19. Concurrency Models in Python"
      ],
      "metadata": {
        "id": "qfkf_xHofK6G"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Big Picture\n",
        "\n",
        "Q. Starting threads and processes is easy enough, but how do you keep track of them?\n",
        "\n",
        "You don't automatically know when it's done, and getting back results or errors requires setting up some communication channel.\n",
        "\n",
        "A courtine is cheap to start. If you start a coroutine using the `await` keyword, it's easy to get a value returned by it, it can be safely cancelled and you have a clear stie to catch exception. But coroutines are often started by async framework and that can make them as hard to monitor as threads or processes."
      ],
      "metadata": {
        "id": "v4537oa8fuaL"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Bit of Jargon\n",
        "\n",
        "* Concurrency\n",
        " - The ability to handle multiple pending tasks, making progress one at a time or in parallel so that each of them eventually succeeds or fails.\n",
        "\n",
        "* Parallelism\n",
        " - The ability to execute multiple computations at the same time. This requires a multicore CPU, multiple CPUs, a GPU or multiple computers in a cluster.\n",
        "\n",
        "* Execution unit\n",
        " - General term for objs that execute code concurrently, each with independent state and call stack. (Python natively supports 3 kinds of execution units: processes, threads and coroutines)\n",
        "\n",
        "* Process\n",
        " - instance of a comp program while it is running, using memory and a slice of CPU time.\n",
        "\n",
        "* Thread\n",
        " - An execution unit within a single process. When a process satrts, it uses a single thread: the main thread. A process can create more threads to operate concurrently by calling operating system APIs. Threads within a process share the same memory space, which holds live Python objects. This allows easy data sharing between threads, but can also lead to corrupted data when more than one thread updates the same obj concurrently.\n",
        "\n",
        "* Coroutine\n",
        " - A fcn that can suspend itself and resume later. In Python, *classic coroutines* are built from generator fcn, and *native coroutines* are defined with `async def`.\n",
        "\n"
      ],
      "metadata": {
        "id": "zcUcgsFPgk2f"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Processes, Threads, and Python's Infamous GIL\n",
        "\n",
        "1. Each instance of Python interpreter is a process. You can start additional Python processes using `multiprocessing` or `concurrent.futures` library. Python's `subprocess` lib is designed to launch processes to run external programs, regardless of the languages used to write them.\n",
        "\n",
        "2. The Python interpreter uses a single thread to run the user's program and the memory garbage collector. You can start additional Python threads using the `threading` or `concurrent.futures` lib.\n",
        "\n",
        "3. Access to object ref counts and other internal interpreter state is controlled by a lock, the Global Interpreter Lock (GIL). Only one python thread can hold the GIL at any time.\n",
        "\n",
        "4. To prevent a Python thread from holding the GIL indefinitely, Python bytecode interpreter pauses the current Python thread every 5ms by default.\n",
        "\n",
        "5. When we write Python code, we have no control over the GIL. but a built-in fcn or an extension written in C (or any lang that interfaces at the Python/C api level) can release the GIL while running time-consuming tasks.\n",
        "\n",
        "6. Every Python standard lib fcn that makes a `syscall` releases the GIL. This includes all fcns that perform disk I/O, network I/O, and `time.sleep()`. Many CPU intensive fcns in the NumPy/SciPy libraries also release the GIL.\n",
        "\n",
        "7. Extensions that integrate at the Python/C API level can also launch other non-Python threads that are not affected by the GIL. Such GIL-free threads generally cannot change Python objs, but they can read from and write to the memory underlying objects that support the \"buffer protocol\" such as `bytearray`, `array.array` and Numpy arrays.\n",
        "\n",
        "8. The effect of the GIL on network programming with Python threads is relatively small, because I/O fcn release the GIL, and r/w to the network always implies high latency. Consequently, each individual thread spends a lot of time waiting anyway, so their execution can be interleaved w/o major impact on the overall throughput.\n",
        "\n",
        "9. Contention over the GIL slows down compute-intensive Python threads. Sequential, single-threaded code is simpler and faster for such tasks.\n",
        "\n",
        "10. To run CPU-intensive Python code on multiple cores, you must use multiple Python processes."
      ],
      "metadata": {
        "id": "260euoLviecZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Concurrent Hello World"
      ],
      "metadata": {
        "id": "nbr4hV9ak_c2"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spinner with Threads\n",
        "\n",
        "Start a fcn that blocs for 3 seconds while animating characters in the terminal to let the user know that the program is \"thinking\" and not stalled."
      ],
      "metadata": {
        "id": "Gj7RtgMulHil"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RPoOBYIoe9CN",
        "outputId": "d83509b1-1a16-4709-a498-bfa400939a4f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Thread(Thread-10 (spin), initial)>\n",
            "| thinking! Answer: 42\n"
          ]
        }
      ],
      "source": [
        "# spinner_thread.py\n",
        "\n",
        "import itertools\n",
        "import time\n",
        "from threading import Thread, Event\n",
        "\n",
        "# This fcn will run in a separate thread\n",
        "# The done arg is an instance of threading.Event\n",
        "# a symple obj to synchronize threads\n",
        "def spin(msg: str, done: Event) -> None:\n",
        "  for char in itertools.cycle(r'\\|/-'): # inf loop\n",
        "    status = f'\\r{char} {msg}' # trick for text-mode anim\n",
        "    # flush=True forcibly flushes the output stream\n",
        "    # independent of what default data buffering the file stream has\n",
        "    print(status, end='', flush=True)\n",
        "    if done.wait(.1): # Event.wait(timeout=None) method returns True\n",
        "    # when the event is set by another thread\n",
        "      break\n",
        "\n",
        "    blanks = ' ' * len(status)\n",
        "    print(f'\\r{blanks}\\r', end='')\n",
        "\n",
        "def slow() -> int:\n",
        "  time.sleep(3) # calling sleep blocks the main thread\n",
        "                # but GIL is released so the spinner thread can proceed\n",
        "  return 42\n",
        "\n",
        "# threading.Event class is Python's simplest signalling mechanism\n",
        "# to coordinate threads\n",
        "# supervisior() returns the result of slow\n",
        "def supervisor() -> int:\n",
        "  done = Event()\n",
        "  spinner = Thread(target=spin, args=('thinking!', done))\n",
        "  print(f'spinner object: {spinner}')\n",
        "  spinner.start() # start the thread\n",
        "  result = slow() # call slow, which blocks the main thread.\n",
        "                  # Meanwhile, the secondary thread is running the spinner anim\n",
        "  done.set() # set the Event flag to True\n",
        "  spinner.join() # wait until the spinner thread finishes\n",
        "  return result\n",
        "\n",
        "def main() -> None:\n",
        "  result = supervisor()\n",
        "  print(f\" Answer: {result}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_thread.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rnC6-engmvW9",
        "outputId": "5040fd35-12b8-4d58-fc3e-63768eec67f0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Thread(Thread-1 (spin), initial)>\n",
            "| thinking! Answer: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Spinner with Processes\n",
        "\n",
        "The `multiprocessing` package supports running concurrent tasks in separate Python processes instead of threads. When you create a `multiprocessing.Process` instance, a whole new Python interpreter is started as a child process in the background."
      ],
      "metadata": {
        "id": "swXp-p4aqae0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spinner_proc.py\n",
        "import itertools\n",
        "import time\n",
        "from multiprocessing import Process, Event\n",
        "from multiprocessing import synchronize # Mypy forces us to import syncrhonize\n",
        "\n",
        "# This fcn will run in a separate thread\n",
        "# The done arg is an instance of threading.Event\n",
        "# a symple obj to synchronize threads\n",
        "def spin(msg: str, done: synchronize.Event) -> None:\n",
        "  for char in itertools.cycle(r'\\|/-'): # inf loop\n",
        "    status = f'\\r{char} {msg}' # trick for text-mode anim\n",
        "    # flush=True forcibly flushes the output stream\n",
        "    # independent of what default data buffering the file stream has\n",
        "    print(status, end='', flush=True)\n",
        "    if done.wait(.1): # Event.wait(timeout=None) method returns True\n",
        "    # when the event is set by another thread\n",
        "      break\n",
        "\n",
        "    blanks = ' ' * len(status)\n",
        "    print(f'\\r{blanks}\\r', end='')\n",
        "\n",
        "def slow() -> int:\n",
        "  time.sleep(3) # calling sleep blocks the main thread\n",
        "                # but GIL is released so the spinner thread can proceed\n",
        "  return 42\n",
        "\n",
        "def supervisor() -> int:\n",
        "  done = Event()\n",
        "  spinner = Process(target=spin, args=('thinking!', done))\n",
        "  print(f\"spinner object: {spinner}\")\n",
        "  spinner.start()\n",
        "  result = slow()\n",
        "  done.set()\n",
        "  spinner.join()\n",
        "  return result\n",
        "\n",
        "def main() -> None:\n",
        "  result = supervisor()\n",
        "  print(f\" Answer: {result}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "pyP0C0ZBmwZR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_proc.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M1_3OdqIrcl1",
        "outputId": "fbf71bfc-f9dc-42c8-c90d-8fa3d981f4b0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Process name='Process-1' parent=13302 initial>\n",
            "| thinking! Answer: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic API of `threading` and `multiprocessing` are simlar but their implementation is very different, and `multiprocessing` has a much larger API to handle the added complexity of multiprocess programming."
      ],
      "metadata": {
        "id": "zh2z_uSYsbWr"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "18:57\n",
        "### Spinner with Coroutines\n",
        "\n",
        "Coroutines are driven by an app-level event loop that manages a queue of pending coroutines, drives them one by one, motitors events triggered by I/O operations initiated by coroutines and passes control back to the corresponding coroutine when each event happens."
      ],
      "metadata": {
        "id": "H6bHEsa8WUAL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# spinner_async.py\n",
        "import itertools\n",
        "import time\n",
        "from multiprocessing import Process, Event\n",
        "from multiprocessing import synchronize # Mypy forces us to import syncrhonize\n",
        "import asyncio\n",
        "\n",
        "async def spin(msg: str) -> None:\n",
        "  for char in itertools.cycle(r'\\|/-'): # inf loop\n",
        "    status = f'\\r{char} {msg}' # trick for text-mode anim\n",
        "    # flush=True forcibly flushes the output stream\n",
        "    # independent of what default data buffering the file stream has\n",
        "    print(status, end='', flush=True)\n",
        "    try:\n",
        "      await asyncio.sleep(.1)\n",
        "    except asyncio.CancelledError:\n",
        "      break\n",
        "\n",
        "    blanks = ' ' * len(status)\n",
        "    print(f'\\r{blanks}\\r', end='')\n",
        "\n",
        "async def slow() -> int:\n",
        "  # await asyncio.sleep(3)\n",
        "  return 42\n",
        "\n",
        "async def supervisor() -> int:\n",
        "  # schedules the eventual execution of spin\n",
        "  # immediately returning an instance of asyncio.Task\n",
        "  spinner = asyncio.create_task(spin(\"thinking!\"))\n",
        "  print(f\"spinner object: {spinner}\")\n",
        "  # blocking supervisor() until slow returns\n",
        "  result = await slow()\n",
        "  # task.cancel method raises a Cancelled Error Exception\n",
        "  # inside the spin coroutine\n",
        "  spinner.cancel()\n",
        "  return result\n",
        "\n",
        "def main() -> None: # only regular fcn defined in this program\n",
        "  # asyncio.run fcn starts the event loop to drive the coroutine that will\n",
        "  # eventually set the other coroutines in motion.\n",
        "  # main fcn will stack blocked until supervision returns\n",
        "  # The return value of `supervisor` will be the return value\n",
        "  # of asyncio.run\n",
        "  result = asyncio.run(supervisor())\n",
        "  print(f\" Answer: {result}\")\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main()"
      ],
      "metadata": {
        "id": "u7VYN0P_reii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Three main ways of running a coroutine:\n",
        " - `asyncio.run(coro())`: Called from a regular fcn to drive a coroutine object that usually is the entry point for all the async code in the program.\n",
        " - `asyncio.create_task(coro())`: Called from a coroutine to schedule another coroutine to execute eventually. It returns a `Task` instance, an object that wraps the coroutine object and provides methods to control and query its state.\n",
        " - `await coro()`: Called from a coroutine to transfer control to the coroutine object returned by `coro()`. This suspends the current coroutine until the body of `coro` returns."
      ],
      "metadata": {
        "id": "41pFIa15Y3NX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_async.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NTo2rQM3Zr2v",
        "outputId": "1a0fb06b-0b25-4893-ae03-bca8e39fc177"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Task pending name='Task-2' coro=<spin() running at /content/spinner_async.py:8>>\n",
            "| thinking! Answer: 42\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## The Real Impact of the GIL"
      ],
      "metadata": {
        "id": "sjOChdUgjbXw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# primes.py\n",
        "import math\n",
        "\n",
        "PRIME_FIXTURE = [\n",
        "    (2, True),\n",
        "    (142702110479723, True),\n",
        "    (299593572317531, True),\n",
        "    (3333333333333301, True),\n",
        "    (3333333333333333, False),\n",
        "    (3333335652092209, False),\n",
        "    (4444444444444423, True),\n",
        "    (4444444444444444, False),\n",
        "    (4444444488888889, False),\n",
        "    (5555553133149889, False),\n",
        "    (5555555555555503, True),\n",
        "    (5555555555555555, False),\n",
        "    (6666666666666666, False),\n",
        "    (6666666666666719, True),\n",
        "    (6666667141414921, False),\n",
        "    (7777777536340681, False),\n",
        "    (7777777777777753, True),\n",
        "    (7777777777777777, False),\n",
        "    (9999999999999917, True),\n",
        "    (9999999999999999, False),\n",
        "]\n",
        "\n",
        "NUMBERS = [n for n, _ in PRIME_FIXTURE]\n",
        "\n",
        "def is_prime(n: int) -> bool:\n",
        "  if n < 2:\n",
        "    return False\n",
        "  if n == 2:\n",
        "    return True\n",
        "  if n % 2 == 0:\n",
        "    return False\n",
        "\n",
        "  root = math.isqrt(n)\n",
        "  for i in range(3, root + 1, 2):\n",
        "    if n % i == 0:\n",
        "      return False\n",
        "  return True"
      ],
      "metadata": {
        "id": "rN3YekQKafrg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "is_prime(5_000_111_000_222_021)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l12r3t5ukCbR",
        "outputId": "9efb8b84-adb3-4a4d-dca0-4451fb39de7a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Quick Quiz\n",
        "\n",
        "What would happen to the spinner animation if you made the following changes, assuming that `n = 5_000_111_000_222_021`\n",
        "\n",
        "1. In spinner_proc.py, replace `time.sleep(3)` with a call to `is_prime(n)`?\n",
        "\n",
        "My answer. As the spinner runs in a seperate process, the program will run as expected."
      ],
      "metadata": {
        "id": "n2hUyOFDkOh9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_proc.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vwFs36z-kGvD",
        "outputId": "0781987f-45af-4d09-d43c-89a715b3c6b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Process name='Process-1' parent=2138 initial>\n",
            "| thinking! Answer: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "2. In spinner_thread.py, replace `time.sleep(3)` with a call to `is_prime(n)`?\n",
        "\n",
        "My answer. Maybe spinner won't work because our `is_prime` does not implement the logic for releasing GIL lock?\n",
        "\n",
        "-> Wrong: Why? the spinner keeps spinning because Python suspends the running thread every 5ms, making the GIL available to other pending threads. Therefore, the main thread running `is_prime` is interrupted every 5ms, allowing the secondary thread to woke up and iterate once through the for loop, until it calls the `wait` method of the `done` event, at which time it will release the GIL.\n",
        "\n",
        "We got away with a compute-intensive task using threading in this simple experiment because there are only two threads: one hogging the CPU, and the other waking up only 10 times per seconds to update the spinner.\n",
        "\n",
        "But if you have two or more threads vying for a lot of CPU times, your program will be slower than sequential code."
      ],
      "metadata": {
        "id": "xj1sDmF6l366"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_thread.py # Oh it works!"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p_7PFq_jll6b",
        "outputId": "de063f9f-9691-4775-ae55-9e24344f6ce1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Thread(Thread-1 (spin), initial)>\n",
            "\\ thinking! Answer: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "3. In spinner_async.py, replace await `asyncio.sleep(3)` with a call to `is_prime(n)`?\n",
        "\n",
        "My answer. As `is_prime` blocks the main thread, the spinner will not work."
      ],
      "metadata": {
        "id": "aTItaiJUoLhX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python spinner_async.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YxhRXzAOm5dO",
        "outputId": "0906eff0-836e-4dac-d89a-aad32914bab8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "spinner object: <Task pending name='Task-2' coro=<spin() running at /content/spinner_async.py:26>>\n",
            "/ thinking! Answer: True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Power Napping with sleep(0)\n",
        "One way to keep the spinner alive is to rewrite `is_prime` as a coroutine and periodically call `asyncio.sleep(0)` in an `await` expression to yield control back to the event loop.\n",
        "\n",
        "However, be aware this will slow down `is_prime` and will slow down the event loop and your whole program with it.\n",
        "\n",
        "Using `await asyncio.sleep(0)` should be considered a stopgap measure before we refactor our async code to delegate CPU-intensive computations to another process."
      ],
      "metadata": {
        "id": "-WuRffuAosQI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## A Homegrown Process Pool\n",
        "\n"
      ],
      "metadata": {
        "id": "xPOggrUCp75P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Use of multiple processes for CPU-intensive tasks and the common pattern of using queues to distribute tasks and collect results\n",
        "\n",
        "Program to compute the primality of a sample of 20 integers from 2 to $10^{16} - 1$"
      ],
      "metadata": {
        "id": "6tvMQtocDgmU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!/usr/bin/env python3\n",
        "\n",
        "# sequential.py\n",
        "\n",
        "from time import perf_counter\n",
        "from typing import NamedTuple\n",
        "\n",
        "from primes import is_prime, NUMBERS\n",
        "\n",
        "class Result(NamedTuple):\n",
        "  # check fcn returns a Result tuple with the boolean value of the is_prime call\n",
        "  # and the elapsed time\n",
        "  prime: bool\n",
        "  elapsed: float\n",
        "\n",
        "def check(n: int) -> Result:\n",
        "  t0 = perf_counter()\n",
        "  prime = is_prime(n)\n",
        "  return Result(prime, perf_counter() - t0)\n",
        "\n",
        "def main() -> None:\n",
        "  print(f\"Checking {len(NUMBERS)} numbers sequentially\")\n",
        "  t0 = perf_counter()\n",
        "  for n in NUMBERS:\n",
        "    # for each number in the sample, we call check and display the result\n",
        "    prime, elapsed = check(n)\n",
        "    label = 'P' if prime else ' '\n",
        "    print(f\"{n:16} {label} {elapsed:9.6f}s\")\n",
        "\n",
        "  elapsed = perf_counter() - t0\n",
        "  print(f\"Total time: {elapsed:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "BNY9Gcuwod6S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python sequential.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d2BsC8k2FQGB",
        "outputId": "c9b0ad1b-17e6-473e-fd7f-1b8c28da1aee"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 20 numbers sequentially\n",
            "               2 P  0.000002s\n",
            " 142702110479723 P  0.781322s\n",
            " 299593572317531 P  1.456853s\n",
            "3333333333333301 P  4.890322s\n",
            "3333333333333333    0.000014s\n",
            "3333335652092209    3.816279s\n",
            "4444444444444423 P  4.972204s\n",
            "4444444444444444    0.000002s\n",
            "4444444488888889    5.297698s\n",
            "5555553133149889    4.999960s\n",
            "5555555555555503 P  6.354240s\n",
            "5555555555555555    0.000015s\n",
            "6666666666666666    0.000001s\n",
            "6666666666666719 P  5.398766s\n",
            "6666667141414921    6.790977s\n",
            "7777777536340681    5.770059s\n",
            "7777777777777753 P  7.135740s\n",
            "7777777777777777    0.000017s\n",
            "9999999999999917 P  6.502389s\n",
            "9999999999999999    0.000013s\n",
            "Total time: 64.17s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import multiprocessing\n",
        "multiprocessing.cpu_count()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l--ETb-8FWFi",
        "outputId": "49ce5eac-0b74-405e-cfd1-f29fa006dfd5"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Code for the Multicore Prime Checker"
      ],
      "metadata": {
        "id": "600edL-IGWzI"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "When we delegate computing to threads or processes, our code does not call the worker function directly, so we can't simply get a return value. Instead, the worker is driven by the thread or process library and it eventually produces a result that needs to be stored somewhere. Coordinating workers and collecting results are common uses of queues in concurrent programming and also in distributed systems"
      ],
      "metadata": {
        "id": "G-rDzrdmGfNA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# procs.py\n",
        "\n",
        "import sys\n",
        "from time import perf_counter\n",
        "from typing import NamedTuple\n",
        "# `multiprocessing` provides multiprocessing.SimpleQueue\n",
        "# but this is a method bound to a predefined instance of lower-level base context class\n",
        "# We must call SimpleQueue to build a queue\n",
        "from multiprocessing import Process, SimpleQueue, cpu_count\n",
        "\n",
        "# multiprocessing.queues has the SimpleQueue class we need for type hints\n",
        "from multiprocessing import queues\n",
        "\n",
        "from primes import is_prime, NUMBERS\n",
        "\n",
        "class PrimeResult(NamedTuple):\n",
        "  n: int\n",
        "  prime: bool\n",
        "  elapsed: float\n",
        "\n",
        "JobQueue = queues.SimpleQueue[int]\n",
        "ResultQueue = queues.SimpleQueue[PrimeResult]\n",
        "\n",
        "def check(n: int) -> PrimeResult:\n",
        "  t0 = perf_counter()\n",
        "  res = is_prime(n)\n",
        "  return PrimeResult(n, res, perf_counter() - t0)\n",
        "\n",
        "# worker gets a queue with the numbers to be checked and another to put result\n",
        "def worker(jobs: JobQueue, results: ResultQueue) -> None:\n",
        "  while n := jobs.get(): # 0 as a poison pill: a signal for the worker to finish\n",
        "    results.put(check(n)) # invoke the primality check and enqueue PrimeResult\n",
        "  results.put(PrimeResult(0, False, 0.0)) # Send back a PrimeResult(0, False, 0.0) to let the main\n",
        "                                          # loop know that this worker is done\n",
        "\n",
        "def start_jobs(\n",
        "    procs: int, jobs: JobQueue, results: ResultQueue # procs is the number of processes\n",
        "                                                    # that will compute the prime checks in parallel\n",
        ") -> None:\n",
        "  for n in NUMBERS:\n",
        "    jobs.put(n) # enqueue the number of processes that will compute the prime checks\n",
        "  for _ in range(procs):\n",
        "    proc = Process(target=worker, args=(jobs, results)) # Fork a child process for each worker\n",
        "    proc.start() # start each child process\n",
        "    jobs.put(0) # enqueue one 0 for each process, to terminate them\n",
        "\n",
        "def main() -> None:\n",
        "  if len(sys.argv) < 2:\n",
        "    procs = cpu_count()\n",
        "  else:\n",
        "    procs = int(sys.argv[1])\n",
        "\n",
        "  print(f\"Checking {len(NUMBERS)} numbers with {procs} processes:\")\n",
        "  t0 = perf_counter()\n",
        "  jobs: JobQueue = SimpleQueue()\n",
        "  results: ResultQueue = SimpleQueue()\n",
        "  start_jobs(procs, jobs, results)\n",
        "  checked = report(procs, results)\n",
        "  elapsed = perf_counter() - t0\n",
        "  print(f\"{checked} checks in {elapsed:.2f}s\")\n",
        "\n",
        "def report(procs: int, results: ResultQueue) -> int:\n",
        "  checked = 0\n",
        "  procs_done = 0\n",
        "  # Loop until all processes are done\n",
        "  while procs_done < procs:\n",
        "    # get one prime result\n",
        "    # calling .get() on a queue block until there is an item in the queue\n",
        "    n, prime, elapsed = results.get()\n",
        "    if n == 0:\n",
        "      # if n == 0, then one process exited; increment procs_done by 1\n",
        "      procs_done += 1\n",
        "    else:\n",
        "      # otherwise increment checked count\n",
        "      checked += 1\n",
        "      label = \"P\" if prime else \" \"\n",
        "      print(f\"{n: 16} {label} {elapsed:9.6f}s\")\n",
        "  return checked\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "y8xALkyeF7cY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Loops, Sentinels, and Poison Pills\n",
        "\n",
        "The `worker` fcn follows a common pattern in concurrent programming: looping indefinitely while taking items from a queue and processing each with a fcn that does the actual work. The loop ends when the queue produces a sentinel value. In this pattern, the sentinel that shuts down the worker is often called a \"poison pill.\""
      ],
      "metadata": {
        "id": "Eql1W7FiJdDE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python procs.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NzdTwaR9JzYx",
        "outputId": "ad594f85-f336-43c7-d8b0-0ad9020c18c7"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 20 numbers with 2 processes:\n",
            "               2 P  0.000010s\n",
            " 142702110479723 P  1.697790s\n",
            " 299593572317531 P  2.398317s\n",
            " 3333333333333333    0.000011s\n",
            " 3333333333333301 P  9.369837s\n",
            " 3333335652092209    9.247227s\n",
            " 4444444444444444    0.000002s\n",
            " 4444444444444423 P 11.750842s\n",
            " 4444444488888889   11.693035s\n",
            " 5555553133149889   12.482119s\n",
            " 5555555555555555    0.000017s\n",
            " 6666666666666666    0.000003s\n",
            " 5555555555555503 P 12.539845s\n",
            " 6666666666666719 P 11.625615s\n",
            " 6666667141414921   11.737624s\n",
            " 7777777536340681   13.163136s\n",
            " 7777777777777777    0.000013s\n",
            " 7777777777777753 P 12.784705s\n",
            " 9999999999999999    0.000013s\n",
            " 9999999999999917 P  8.166087s\n",
            "20 checks in 68.28s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "UVgiX4okLLeZ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}