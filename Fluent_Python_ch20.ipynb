{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNx8vDSIgP2L9S09JwPMj4c"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 20. Concurrent Execution"
      ],
      "metadata": {
        "id": "jI5LFWi-8mZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chapter focuses on `concurrent.futures.Executor` classes that encapuslate the pattern of \"spawning a bunch of independent threads and collecting the results in a queue\"\n",
        "\n",
        "Here the author introduces the concept of \"futures\"--objects representing the asynchronous execution of an operation, similar to JS promises.\n",
        "\n",
        "Executors are the most important high-level feature while futures are low-level objects."
      ],
      "metadata": {
        "id": "bekz_MFm84sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concurrent Web Downloads\n",
        "\n",
        "Concurrency is essential for efficient network I/O: instead of idly waiting for remote machines, the application should do sth else until a response comes back.\n",
        "\n",
        "Three simples programs to download images of 20 country flags from the web\n",
        " - `flags.py`: runs sequentially\n",
        " - `flags_threadpool.py` uses the `concurrent.futures` pacakge\n",
        " - `flags_asyncio.py` uses the `asyncio`"
      ],
      "metadata": {
        "id": "vqVcUlOI9czu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Sequential Download Script"
      ],
      "metadata": {
        "id": "IoDIWaO--W4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpx"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35kvnyfA9sH",
        "outputId": "9d0af654-4681-4f9b-dac1-b969a6c777bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Callable\n",
        "\n",
        "import httpx\n",
        "\n",
        "POP20_CC = ('CN IN US ID BR PK NG BD RU KR '\n",
        "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
        "\n",
        "BASE_URL = 'https://www.fluentpython.com/data/flags'\n",
        "DEST_DIR = Path('downloaded')\n",
        "\n",
        "# save the img bytes to filename in the DEST_DIR\n",
        "def save_flag(img: bytes, filenames: str) -> None:\n",
        "  (DEST_DIR / filename).write_bytes(img)\n",
        "\n",
        "def get_flag(cc: str) -> bytes:\n",
        "  url = f'{BASE_URL}/{cc}/{cc}.gif'.lower()\n",
        "  resp = httpx.get(url, timeout=6.1, # it's a good practice to add a sensible timeout\n",
        "                   follow_redirects=True) # By default, HTTPX does not follow redirects\n",
        "  resp.raise_for_status()\n",
        "  return resp.content\n",
        "\n",
        "# key function to compare with the concurrent implementations\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "  for cc in sorted(cc_list):\n",
        "    image = get_flag(cc)\n",
        "    save_flag(image, f'{cc}.gif')\n",
        "    print(cc, end=\" \", flush=True) # display one country code at a time in the same line\n",
        "                                   # flush=True is needed because by default Python output is line buffered\n",
        "  return len(cc_list)\n",
        "\n",
        "def main(downloader: Callable[[list[str]], int]) -> None:\n",
        "  DEST_DIR.mkdir(exist_ok=True)\n",
        "  t0 = time.perf_counter()\n",
        "  count = downloader(POP20_CC)\n",
        "  elapsed = time.perf_counter() - t0\n",
        "  print(f\"\\n{count} downloads in {elapsed:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n"
      ],
      "metadata": {
        "id": "A9JAwPWQ-WsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuEwg8zw8kL4",
        "outputId": "18a17f53-2bcf-4526-e112-c139a0010934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BD BR CD CN DE EG ET FR ID IN IR KR MX NG PH PK RU TR US VN \n",
            "20 downloads in 6.43s\n"
          ]
        }
      ],
      "source": [
        "!python flags.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading with concurrent.futures"
      ],
      "metadata": {
        "id": "NZENI7MNBVjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Features: `ThreadPoolExecutor` and `ProcessPoolExectuor` classes, which implement an API to submit cllables for execution in different threads or processes. The classes transparently manage a pool of worker threads or processes, and queues to distribute jobs and collect results."
      ],
      "metadata": {
        "id": "GDYjWHmrBYPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags_threadpool.py\n",
        "from concurrent import futures\n",
        "\n",
        "from flags import save_flag, get_flag, main\n",
        "\n",
        "def download_one(cc: str):\n",
        "  image = get_flag(cc)\n",
        "  save_flag(image, f'{cc}.gif')\n",
        "  print(cc, end=\" \", flush=True)\n",
        "  return cc\n",
        "\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "  # instantiate the thread pool executor as a context manager\n",
        "  # exectuor.__exit__ will call executor.shutdown(wait=True) which will block until all threads are done\n",
        "  with futures.ThreadPoolExecutor() as executor:\n",
        "    res = executor.map(download_one, sorted(cc_list))\n",
        "\n",
        "  return len(list(res))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n",
        "\n"
      ],
      "metadata": {
        "id": "IOEmKlPTA70y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python flags_threadpool.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_hc9R0C5HQ",
        "outputId": "dd97d199-65b7-49c2-9c80-3dd6e1274df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BD CN DE BR EG CD ET ID FR KR IN IR MX NG PH RU PK TR US VN \n",
            "20 downloads in 1.29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count() + 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxdiwF5EC_xi",
        "outputId": "d8bb7d9d-122a-429e-91df-bb50d351208e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Where are teh Futures?\n",
        "\n",
        "Futures are core components of `concurrent.futures` and of `asyncio` but as users of these libraries we sometimes don't see them.\n",
        "\n",
        "There are two classes naemd `Future` in the standard library: `concurrent.futures.Future` and `asyncio.Future`. They serve the same purpose: an instance of either `Future` class represents a deferred computation that may or may not have completed.\n",
        "\n",
        "Futures encapsulate pending operations so that we can put them in queues, check whether they are done, and retrieve results when they become available.\n",
        "\n",
        "We should not create them: they are meant to be instantiated exclusively by the concurrency framework, be it `concurrent.futures` or `asyncio`. Why? a `Future` represents something that will eventually run, therefore it must be scheduled to run, and that's the job of the framework.\n",
        "\n",
        "Application code is not supposed to change the state of the a future: the concurrency framework changes the state of a future when the computation it represents is done, and we can't control when that happens.\n",
        "\n",
        "Both types of `Future` have a `.done()` method that is nonblocking and returns a Boolean that tells you whether the callable wrapped by that future has executed or not. However, instaed of repeatedly asking whether a future is done, client code usually asks to be notified. That's why both `Future` classes have an `.add_done_callback()` method.\n",
        "\n",
        "There is also a `.result()` method, which works the same in both classes when the future is done: it returns the result of the callable, or re-raises whatever exception might have been thrown when the callable was executed. However, when the future is not done, the behavior of the `result` method is very different."
      ],
      "metadata": {
        "id": "gmb6b1Bne70O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags_threadpool_futures.py\n",
        "from concurrent import futures\n",
        "\n",
        "from flags import save_flag, get_flag, main\n",
        "\n",
        "def download_one(cc: str):\n",
        "  image = get_flag(cc)\n",
        "  save_flag(image, f'{cc}.gif')\n",
        "  print(cc, end=\" \", flush=True)\n",
        "  return cc\n",
        "\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "\n",
        "  cc_list = cc_list[:5] # just for this demonstration\n",
        "  # instantiate the thread pool executor as a context manager\n",
        "  # exectuor.__exit__ will call executor.shutdown(wait=True) which will block until all threads are done\n",
        "  with futures.ThreadPoolExecutor(max_workers=3) as executor: # max_workers=3 to see pending futures in the output\n",
        "    to_do: list[futures.Future] = []\n",
        "    for cc in sorted(cc_list):\n",
        "      future = executor.submit(download_one, cc)\n",
        "      to_do.append(future)\n",
        "      print(f\"Scheduled for {cc}: {future}\")\n",
        "\n",
        "    for count, future in enumerate(futures.as_completed(to_do), 1):\n",
        "      res: str = future.result()\n",
        "      print(f\"{future} result: {res!r}\")\n",
        "\n",
        "  return count\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n",
        "\n"
      ],
      "metadata": {
        "id": "4jSjKgBPDQ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`concurrent.futures.as_completed` function takes an iterable of futures and returns an iterator that yields futures as they are done.\n",
        "\n",
        "The higher-level `executor.map` is replaced by two `for` loops: one to create and schedule the futures, the other to retrieve their results. While we are at it, we'll add a few `print` calls to display each future before and after it's done."
      ],
      "metadata": {
        "id": "ZpLBSvAph8-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python flags_threadpool_futures.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPxVT7umh8a7",
        "outputId": "50bfe5a1-335b-46ed-cf73-e346b0488162"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduled for BR: <Future at 0x799001ff6260 state=running>\n",
            "Scheduled for CN: <Future at 0x799001d70c10 state=running>\n",
            "Scheduled for ID: <Future at 0x799001d71480 state=running>\n",
            "Scheduled for IN: <Future at 0x799001d71d80 state=pending>\n",
            "Scheduled for US: <Future at 0x799001d71db0 state=pending>\n",
            "CN <Future at 0x799001d70c10 state=finished returned str> result: 'CN'\n",
            "ID <Future at 0x799001d71480 state=finished returned str> result: 'ID'\n",
            "BR <Future at 0x799001ff6260 state=finished returned str> result: 'BR'\n",
            "IN <Future at 0x799001d71d80 state=finished returned str> result: 'IN'\n",
            "US <Future at 0x799001d71db0 state=finished returned str> result: 'US'\n",
            "\n",
            "5 downloads in 0.35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a brief look at a simple way to work around the GIL for CPU-bound jobs using `concurrent.futures`.\n",
        "\n",
        "## Launching Processes with concurrent.futures\n",
        "\n",
        "The real value of `ProcessPoolExecutor` is in CPU-intensive jobs."
      ],
      "metadata": {
        "id": "Tx7CvjtYjbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# proc_pool.py\n",
        "\n",
        "import sys\n",
        "from concurrent import futures # hides multiprocessing / SimpleQueue / etc\n",
        "from time import perf_counter\n",
        "from typing import NamedTuple\n",
        "\n",
        "from primes import is_prime, NUMBERS\n",
        "\n",
        "class PrimeResult(NamedTuple):\n",
        "  n: int\n",
        "  flag: bool\n",
        "  elapsed: float\n",
        "\n",
        "def check(n: int) -> PrimeResult:\n",
        "  t0 = perf_counter()\n",
        "  res = is_prime(n)\n",
        "  return PrimeResult(n, res, perf_counter() - t0)\n",
        "\n",
        "def main() -> None:\n",
        "  if len(sys.argv) < 2:\n",
        "    workers = None\n",
        "  else:\n",
        "    workers = int(sys.argv[1])\n",
        "\n",
        "  executor = futures.ProcessPoolExecutor(workers)\n",
        "  actual_workers = executor._max_workers # type: ignore\n",
        "\n",
        "  print(f\"Checking {len(NUMBERS)} numbers with {actual_workers} processes:\")\n",
        "\n",
        "  t0 = perf_counter()\n",
        "\n",
        "  numbers = sorted(NUMBERS, reverse=True)\n",
        "  with executor:\n",
        "    # executor.map() returns the result in the same order as the numbers are given\n",
        "    for n, prime, elapsed in executor.map(check, numbers):\n",
        "      label = 'P' if prime else ' '\n",
        "      print(f\"{n: 16}   {label} {elapsed:9.6f}s\")\n",
        "\n",
        "  time = perf_counter() - t0\n",
        "  print(f\"Total time: {time:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "g4JXyJboiyXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python proc_pool.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejfDcgP4lhrD",
        "outputId": "fce99851-5c98-4933-c9d3-bc6e5dcee58d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 20 numbers with 2 processes:\n",
            " 9999999999999999      0.000036s\n",
            " 9999999999999917   P 15.200927s\n",
            " 7777777777777777      0.000005s\n",
            " 7777777777777753   P 13.473852s\n",
            " 7777777536340681     13.214291s\n",
            " 6666667141414921     12.325249s\n",
            " 6666666666666719   P 12.355056s\n",
            " 6666666666666666      0.000002s\n",
            " 5555555555555555      0.000009s\n",
            " 5555555555555503   P 11.451030s\n",
            " 5555553133149889     12.853707s\n",
            " 4444444488888889     11.632231s\n",
            " 4444444444444444      0.000002s\n",
            " 4444444444444423   P  9.667734s\n",
            " 3333335652092209      8.738373s\n",
            " 3333333333333333      0.000010s\n",
            " 3333333333333301   P  6.512187s\n",
            " 299593572317531   P  2.902751s\n",
            " 142702110479723   P  1.590411s\n",
            "               2   P  0.000002s\n",
            "Total time: 66.87s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Experimenting with `Executor.map`\n"
      ],
      "metadata": {
        "id": "cdivcSe4RdHg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Experiment that may help us visualize the operation of `Executor.map`"
      ],
      "metadata": {
        "id": "FuWaJSrrRsN0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# demo_executor_map.py\n",
        "\n",
        "from time import sleep, strftime\n",
        "from concurrent import futures\n",
        "\n",
        "def display(*args):\n",
        "  \"\"\"this function simply prints whatever argument it gets, preceded by a timestamp in [HH:MM:SS]\"\"\"\n",
        "  print(strftime('[%H:%M:%S]'), end=' ')\n",
        "  print(*args)\n",
        "\n",
        "def loiter(n):\n",
        "  \"\"\"loiter does nothing except display a message when it starts, sleep for n seconds, then display a message when it ends\"\"\"\n",
        "  msg = '{}loiter({}): doing nothing for {}s'\n",
        "  display(msg.format('\\t' * n, n, n))\n",
        "  sleep(n)\n",
        "  msg = '{}loiter({}): done.'\n",
        "  display(msg.format('\\t'*n, n))\n",
        "  return n * 10\n",
        "\n",
        "def main():\n",
        "  display('Script starting')\n",
        "  executor = futures.ThreadPoolExecutor(max_workers=3)\n",
        "  results = executor.map(loiter, range(5))\n",
        "  display('results:', results)\n",
        "  display('waiting for individual results:')\n",
        "\n",
        "  # enumerate call in the for loop will implicitly invoke next(results)\n",
        "  # which in turn will invoke _f.result() on the _f future representing the first call\n",
        "  for i, result in enumerate(results):\n",
        "    display(f\"result {i}: {result}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()\n",
        "\n"
      ],
      "metadata": {
        "id": "k5SCE4nFligQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0ef419c9-fc25-4232-d3a6-ed05a4a277bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:46:39] Script starting\n",
            "[02:46:39][02:46:39] \tloiter(1): doing nothing for 1s\n",
            "[02:46:39][02:46:39] results: <generator object Executor.map.<locals>.result_iterator at 0x7f1951a62ab0>\n",
            "[02:46:39] waiting for individual results:\n",
            " \t\tloiter(2): doing nothing for 2s\n",
            " loiter(0): doing nothing for 0s\n",
            "[02:46:39] loiter(0): done.\n",
            "[02:46:39] \t\t\tloiter(3): doing nothing for 3s\n",
            "[02:46:39] result 0: 0\n",
            "[02:46:40] \tloiter(1): done.\n",
            "[02:46:40] \t\t\t\tloiter(4): doing nothing for 4s\n",
            "[02:46:40] result 1: 10\n",
            "[02:46:41] \t\tloiter(2): done.\n",
            "[02:46:41] result 2: 20\n",
            "[02:46:42] \t\t\tloiter(3): done.\n",
            "[02:46:42] result 3: 30\n",
            "[02:46:44] \t\t\t\tloiter(4): done.\n",
            "[02:46:44] result 4: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python demo_executor_map.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zGmGbTYfTNKe",
        "outputId": "08f574a3-03d0-444f-eb62-57abbdad7807"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[02:46:44] Script starting\n",
            "[02:46:44] loiter(0): doing nothing for 0s\n",
            "[02:46:44] loiter(0): done.\n",
            "[02:46:44] \tloiter(1): doing nothing for 1s\n",
            "[02:46:44] \t\tloiter(2): doing nothing for 2s\n",
            "[02:46:44] \t\t\tloiter(3): doing nothing for 3s\n",
            "[02:46:44] results: <generator object Executor.map.<locals>.result_iterator at 0x7f5173e73d10>\n",
            "[02:46:44] waiting for individual results:\n",
            "[02:46:44] result 0: 0\n",
            "[02:46:45] \tloiter(1): done.\n",
            "[02:46:45] \t\t\t\tloiter(4): doing nothing for 4s\n",
            "[02:46:45] result 1: 10\n",
            "[02:46:46] \t\tloiter(2): done.\n",
            "[02:46:46] result 2: 20\n",
            "[02:46:47] \t\t\tloiter(3): done.\n",
            "[02:46:47] result 3: 30\n",
            "[02:46:49] \t\t\t\tloiter(4): done.\n",
            "[02:46:49] result 4: 40\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The `Executor.map` function is easy to use, but often it's perferable to get the results as they are ready, regardless of the order they were submitted. To do that, we need a combination of the `Executor.submit` method and the `future.as_completed` function."
      ],
      "metadata": {
        "id": "nBcRX-eKWDPV"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Downloads with Progress Display and Error Handling"
      ],
      "metadata": {
        "id": "B7wCdNcDWXpZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "`flags2_common.py` contains common functions and settings used by all flags2 examples, including a `main` function, which takes care of command-line parsing, timing, and reporting results."
      ],
      "metadata": {
        "id": "oH1-4CYWXgc2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags2_common.py\n",
        "\n",
        "import argparse\n",
        "import string\n",
        "import sys\n",
        "import time\n",
        "from collections import Counter\n",
        "from enum import Enum\n",
        "from pathlib import Path\n",
        "\n",
        "DownloadStatus = Enum('DownloadStatus', 'OK NOT_FOUND ERROR')\n",
        "\n",
        "POP20_CC = ('CN IN US ID BR PK NG BD RU KR '\n",
        "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
        "\n",
        "DEFAULT_CONCUR_REQ = 1\n",
        "MAX_CONCUR_REQ = 1\n",
        "\n",
        "SERVERS = {\n",
        "    'REMOTE': 'https://www.fluentpython.com/data/flags',\n",
        "    'LOCAL':  'http://localhost:8000/flags',\n",
        "    'DELAY':  'http://localhost:8001/flags',\n",
        "    'ERROR':  'http://localhost:8002/flags',\n",
        "}\n",
        "DEFAULT_SERVER = 'LOCAL'\n",
        "\n",
        "DEST_DIR = Path('downloaded')\n",
        "COUNTRY_CODES_FILE = Path('country_codes.txt')\n",
        "\n",
        "def save_flag(img: bytes, filename: str) -> None:\n",
        "  (DEST_DIR / filename).write_bytes(img)\n",
        "\n",
        "def initial_report(cc_list: list[str],\n",
        "                   actual_req: int,\n",
        "                   server_label: str) -> None:\n",
        "  if len(cc_list) <= 10:\n",
        "    cc_msg = ', '.join(cc_list)\n",
        "  else:\n",
        "    cc_msg = f'from {cc_list[0]} to {cc_list[-1]}'\n",
        "  print(f'{server_label} site: {SERVERS[server_label]}')\n",
        "  plural = 's' if len(cc_list) != 1 else ''\n",
        "  print(f'Searching for {len(cc_list)} flag{plural}: {cc_msg}')\n",
        "\n",
        "  if actual_req == 1:\n",
        "    print('1 connection will be used')\n",
        "  else:\n",
        "    print(f'{actual_req} concurrent connections will be used.')\n",
        "\n",
        "def final_report(cc_list: list[str],\n",
        "                 counter: Counter[DownloadStatus],\n",
        "                 start_time: float) -> None:\n",
        "  elapsed = time.perf_counter() - start_time\n",
        "  print('-' * 20)\n",
        "  plural = 's' if counter[DownloadStatus.OK] != 1 else ''\n",
        "  print(f'{counter[DownloadStatus.OK]:3} flag{plural} downloaded.')\n",
        "  if counter[DownloadStatus.NOT_FOUND]:\n",
        "    print(f'{counter[DownloadStatus.NOT_FOUND]:3} not found.')\n",
        "  if counter[DownloadStatus.ERROR]:\n",
        "    plural = 's' if counter[DownloadStatus.ERROR] != 1 else ''\n",
        "    print(f'{counter[DownloadStatus.ERROR]:3} error{plural}.')\n",
        "  print(f'Elapsed time: {elapsed:.2f}s')\n",
        "\n",
        "def expand_cc_args(every_cc: bool,\n",
        "                   all_cc: bool,\n",
        "                   cc_args: list[str],\n",
        "                   limit: int) -> list[str]:\n",
        "  codes: set[str] = set()\n",
        "  A_Z = string.ascii_uppercase\n",
        "  if every_cc:\n",
        "    codes.update(a + b for a in A_Z for b in A_Z)\n",
        "  elif all_cc:\n",
        "    text = COUNTRY_CODES_FILE.read_text()\n",
        "    codes.update(text.split())\n",
        "  else:\n",
        "    for cc in (c.upper() for c in cc_args):\n",
        "      if len(cc) == 1 and cc in A_Z:\n",
        "        codes.update(cc + c for c in A_Z)\n",
        "      elif len(cc) == 2 and all(c in A_Z for c in cc):\n",
        "        codes.add(cc)\n",
        "      else:\n",
        "        raise ValueError('*** Usage error: each CC argument '\n",
        "                          'must be A to Z or AA to ZZ.')\n",
        "  return sorted(codes)[:limit]\n",
        "\n",
        "def process_args(default_concur_req):\n",
        "  server_options = ', '.join(sorted(SERVERS))\n",
        "  parser = argparse.ArgumentParser(\n",
        "      description='Download flags for country codes. '\n",
        "                  'Default: top 20 countries by population'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      'cc', metavar='CC', nargs='*',\n",
        "      help='country code or 1st letter (eg. B for BA...BZ)'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-a', '--all', action='store_true',\n",
        "      help='get all available flags (AD to ZW)'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-e', '--every', action='store_true',\n",
        "      help='get flags for every possible code (AA ... AZ)'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-l', '--limit', metavar='N', type=int, help='limit to N first codes',\n",
        "      default=sys.maxsize\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-m', '--max_req', metavar='CONCURRENT' , type=int,\n",
        "      default=default_concur_req,\n",
        "      help=f'maximum concurrent requests (default={default_concur_req})'\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-s', '--server', metavar='LABEL', default=DEFAULT_SERVER,\n",
        "      help=f\"Server to hit; one of {server_options} \"\n",
        "           f\"(default={DEFAULT_SERVER})\"\n",
        "  )\n",
        "\n",
        "  parser.add_argument(\n",
        "      '-v', '--verbose', action='store_true',\n",
        "      help='output detailed progress info'\n",
        "  )\n",
        "\n",
        "  args = parser.parse_args()\n",
        "\n",
        "  if args.max_req < 1:\n",
        "    print('*** Usage error: --mx_req CONCURRENT must be >= 1')\n",
        "    parser.print_usage()\n",
        "    sys.exit(2)\n",
        "  if args.limit < 1:\n",
        "    print('*** Usage error: --limit N must be >= 1')\n",
        "    parser.print_usage()\n",
        "    sys.exit(2)\n",
        "\n",
        "  args.server = args.server.upper()\n",
        "  if args.server not in SERVERS:\n",
        "    print(f\"*** Usage error: --server LABEL \"\n",
        "          f\"must be one of {server_options}\")\n",
        "    parser.print_usage()\n",
        "    sys.exit(2)\n",
        "\n",
        "  try:\n",
        "    cc_list = expand_cc_args(args.every, args.all, args.cc, args.limit)\n",
        "  except ValueError as err:\n",
        "    print(err.args[0])\n",
        "    parser.print_usage()\n",
        "    sys.exit(2)\n",
        "\n",
        "  if not cc_list:\n",
        "    cc_list = sorted(POP20_CC)[:args.limit]\n",
        "  return args, cc_list\n",
        "\n",
        "def main(download_many, default_concur_req, max_concur_req):\n",
        "  args, cc_list = process_args(default_concur_req)\n",
        "  actual_req = min(args.max_req, max_concur_req, len(cc_list))\n",
        "  initial_report(cc_list, actual_req, args.server)\n",
        "  base_url = SERVERS[args.server]\n",
        "  DEST_DIR.mkdir(exist_ok=True)\n",
        "  t0 = time.perf_counter()\n",
        "  counter = download_many(cc_list, base_url, args.verbose, actual_req)\n",
        "  final_report(cc_list, counter, t0)\n",
        "\n"
      ],
      "metadata": {
        "id": "cMtcxE9vTPB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from tqdm import tqdm\n",
        "for i in tqdm(range(1000)):\n",
        "  time.sleep(0.01)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1rCzqxHdez1",
        "outputId": "33457da4-23f5-4770-dd10-9ba6c85d5f7e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1000/1000 [00:10<00:00, 97.32it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from google.colab import files\n",
        "!wget \"https://github.com/fluentpython/example-code-2e/raw/master/20-executors/getflags/flags.zip\""
      ],
      "metadata": {
        "id": "mtQF_Ehrd0jH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!unzip flags.zip -d ."
      ],
      "metadata": {
        "id": "dIlTHi19e7he"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "J1N1pnVuUHBC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# flags2_sequential.py\n",
        "\n",
        "from collections import Counter\n",
        "from http import HTTPStatus\n",
        "\n",
        "import httpx\n",
        "import tqdm\n",
        "\n",
        "from flags2_common import main, save_flag, DownloadStatus\n",
        "\n",
        "DEFAULT_CONCUR_REQ = 1\n",
        "MAX_CONCUR_REQ = 1\n",
        "\n",
        "def get_flag(base_url: str, cc: str) -> bytes:\n",
        "  url = f'{base_url}/{cc}/{cc}.gif'.lower()\n",
        "  resp = httpx.get(url, timeout=3.1, follow_redirects=True)\n",
        "  resp.raise_for_status() # Raises HTTPStatusError\n",
        "                          # if the HTTP status code is not is range(200, 300)\n",
        "  return resp.content\n",
        "\n",
        "def download_one(cc: str, base_url: str, verbose: bool = False) -> DownloadStatus:\n",
        "  try:\n",
        "    image = get_flag(base_url, cc)\n",
        "  except httpx.HTTPStatusError as exc:\n",
        "    res = exc.response\n",
        "    if res.status_code == HTTPStatus.NOT_FOUND:\n",
        "      # catches HTTPStatusError to handle HTTP code 404\n",
        "      # by setting its local status to DownloadStatus.NOT_FOUND\n",
        "      status = DownloadStatus.NOT_FOUND\n",
        "      msg = f\"not found: {res.url}\"\n",
        "    else:\n",
        "      raise\n",
        "  else:\n",
        "    save_flag(image, f'{cc}.gif')\n",
        "    status = DownloadStatus.OK\n",
        "    msg = 'OK'\n",
        "\n",
        "  if verbose:\n",
        "    print(cc, msg)\n",
        "\n",
        "  return status\n",
        "\n",
        "def download_many(cc_list: list[str], base_url: str,\n",
        "                  verbose: bool, _unused_concur_req: int) -> Counter[DownloadStatus]:\n",
        "  counter: Counter[DownloadStatus] = Counter()\n",
        "  cc_iter = sorted(cc_list)\n",
        "  if not verbose:\n",
        "    cc_iter = tqdm.tqdm(cc_iter)\n",
        "  for cc in cc_iter:\n",
        "    try:\n",
        "      status = download_one(cc, base_url, verbose)\n",
        "    # Exceptions raised by get_flag and not handled by download_one are handled here\n",
        "    except httpx.HTTPStatusError as exc:\n",
        "      error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}'\n",
        "      error_msg = error_msg.format(resp=exc.response)\n",
        "    # Other network-related exceptions are handled here\n",
        "    except httpx.RequestError as exc:\n",
        "      error_msg = f'{exc} {type(exc)}'.strip()\n",
        "    # Exit the loop if the user hits Ctrl-C\n",
        "    except KeyboardInterrupt:\n",
        "      break\n",
        "    # If no exception escaped download_one, clear the error msg\n",
        "    else:\n",
        "      error_msg = ''\n",
        "\n",
        "    if error_msg:\n",
        "      status = DownloadStatus.ERROR\n",
        "    counter[status] += 1\n",
        "    if verbose and error_msg:\n",
        "      print(f'{cc} error: {error_msg}')\n",
        "\n",
        "  return counter"
      ],
      "metadata": {
        "id": "-dPjHbcDfI5N"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Using futures.as_completed\n",
        "\n",
        "In order to integrate the `tqdm` progress bar and handle errors on each request, the `flags2_threadpool.py` script uses `futures.ThreadpoolExecutor` with the `futures.as_completed` function we've already seen."
      ],
      "metadata": {
        "id": "XHbIuYawaZKc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags2_threadpool.py\n",
        "\n",
        "from collections import Counter\n",
        "from concurrent.futures import ThreadPoolExecutor, as_completed\n",
        "\n",
        "import httpx\n",
        "import tqdm\n",
        "\n",
        "from flags2_common import main, DownloadStatus\n",
        "from flags2_sequential import download_one\n",
        "\n",
        "# If the -m/--max_req command-line option is not given,\n",
        "# this will be the maximum # of concurrent requests\n",
        "DEFAULT_CONCUR_REQ = 30\n",
        "# caps the maximum number of concurrent requests\n",
        "# in order to prevent significant memory overhead\n",
        "# caused by launching too many threads\n",
        "MAX_CONCUR_REQ = 1000\n",
        "\n",
        "def download_many(cc_list: list[str], base_url: str,\n",
        "                  verbose: bool, concur_req: int) -> Counter[DownloadStatus]:\n",
        "  counter: Counter[DownloadStatus] = Counter()\n",
        "  with ThreadPoolExecutor(max_workers=concur_req) as executor:\n",
        "    to_do_map = {} # this dict will map each Future instance with\n",
        "                   # the respective country code for error reporting\n",
        "    for cc in sorted(cc_list):\n",
        "      future = executor.submit(download_one, cc, base_url, verbose)\n",
        "      to_do_map[future] = cc # store the future and the country code in the dict\n",
        "    done_iter = as_completed(to_do_map) # returns an iterator that yields futures as each task is done\n",
        "    if not verbose:\n",
        "      done_iter = tqdm.tqdm(done_iter, total=len(cc_list))\n",
        "    # Iterate over the futures as they are completed\n",
        "    for future in done_iter:\n",
        "      try:\n",
        "        # calling a result method on a future\n",
        "        # either (1) returns the value returned by the callable\n",
        "        #     or (2) raises whatever exception was caught when the callable was executed\n",
        "        status = future.result()\n",
        "      except httpx.HTTPStatusError as exc:\n",
        "        error_msg = 'HTTP error {resp.status_code} - {resp.reason_phrase}'\n",
        "        error_msg = error_msg.format(resp=exc.response)\n",
        "      # Other network-related exceptions are handled here\n",
        "      except httpx.RequestError as exc:\n",
        "        error_msg = f'{exc} {type(exc)}'.strip()\n",
        "      # Exit the loop if the user hits Ctrl-C\n",
        "      except KeyboardInterrupt:\n",
        "        break\n",
        "      # If no exception escaped download_one, clear the error msg\n",
        "      else:\n",
        "        error_msg = ''\n",
        "\n",
        "      if error_msg:\n",
        "        status = DownloadStatus.ERROR\n",
        "      counter[status] += 1\n",
        "      if verbose and error_msg:\n",
        "        cc = to_do_map[future] # to provide context for the error message\n",
        "        print(f'{cc} error: {error_msg}')\n",
        "  return counter\n",
        "\n",
        "if __name__ == '__main__':\n",
        "  main(download_many, DEFAULT_CONCUR_REQ, MAX_CONCUR_REQ)\n",
        ""
      ],
      "metadata": {
        "id": "VZbfT5uvaV8P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Python threads are well suited for I/O intensive applications and the `concurrent.futures` package makes it relatively simple to use for certain use cases.\n",
        "\n",
        "With `ProcessPoolExecutor`, you can also solve CPU-intensive problems on multiple cores."
      ],
      "metadata": {
        "id": "NIlusmxhedjO"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "gqAaorgXexdS"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}