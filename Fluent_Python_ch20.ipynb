{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMrZtnqgDyabBq6QOrJ6nyT"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Chapter 20. Concurrent Execution"
      ],
      "metadata": {
        "id": "jI5LFWi-8mZb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This chapter focuses on `concurrent.futures.Executor` classes that encapuslate the pattern of \"spawning a bunch of independent threads and collecting the results in a queue\"\n",
        "\n",
        "Here the author introduces the concept of \"futures\"--objects representing the asynchronous execution of an operation, similar to JS promises.\n",
        "\n",
        "Executors are the most important high-level feature while futures are low-level objects."
      ],
      "metadata": {
        "id": "bekz_MFm84sx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Concurrent Web Downloads\n",
        "\n",
        "Concurrency is essential for efficient network I/O: instead of idly waiting for remote machines, the application should do sth else until a response comes back.\n",
        "\n",
        "Three simples programs to download images of 20 country flags from the web\n",
        " - `flags.py`: runs sequentially\n",
        " - `flags_threadpool.py` uses the `concurrent.futures` pacakge\n",
        " - `flags_asyncio.py` uses the `asyncio`"
      ],
      "metadata": {
        "id": "vqVcUlOI9czu"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### A Sequential Download Script"
      ],
      "metadata": {
        "id": "IoDIWaO--W4C"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install httpx"
      ],
      "metadata": {
        "collapsed": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c35kvnyfA9sH",
        "outputId": "9d0af654-4681-4f9b-dac1-b969a6c777bb"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting httpx\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/75.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/77.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: idna in /usr/local/lib/python3.10/dist-packages (from httpx) (3.7)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from httpx) (1.3.1)\n",
            "Collecting h11<0.15,>=0.13 (from httpcore==1.*->httpx)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio->httpx) (1.2.1)\n",
            "Installing collected packages: h11, httpcore, httpx\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "from pathlib import Path\n",
        "from typing import Callable\n",
        "\n",
        "import httpx\n",
        "\n",
        "POP20_CC = ('CN IN US ID BR PK NG BD RU KR '\n",
        "            'MX PH VN ET EG DE IR TR CD FR').split()\n",
        "\n",
        "BASE_URL = 'https://www.fluentpython.com/data/flags'\n",
        "DEST_DIR = Path('downloaded')\n",
        "\n",
        "# save the img bytes to filename in the DEST_DIR\n",
        "def save_flag(img: bytes, filenames: str) -> None:\n",
        "  (DEST_DIR / filename).write_bytes(img)\n",
        "\n",
        "def get_flag(cc: str) -> bytes:\n",
        "  url = f'{BASE_URL}/{cc}/{cc}.gif'.lower()\n",
        "  resp = httpx.get(url, timeout=6.1, # it's a good practice to add a sensible timeout\n",
        "                   follow_redirects=True) # By default, HTTPX does not follow redirects\n",
        "  resp.raise_for_status()\n",
        "  return resp.content\n",
        "\n",
        "# key function to compare with the concurrent implementations\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "  for cc in sorted(cc_list):\n",
        "    image = get_flag(cc)\n",
        "    save_flag(image, f'{cc}.gif')\n",
        "    print(cc, end=\" \", flush=True) # display one country code at a time in the same line\n",
        "                                   # flush=True is needed because by default Python output is line buffered\n",
        "  return len(cc_list)\n",
        "\n",
        "def main(downloader: Callable[[list[str]], int]) -> None:\n",
        "  DEST_DIR.mkdir(exist_ok=True)\n",
        "  t0 = time.perf_counter()\n",
        "  count = downloader(POP20_CC)\n",
        "  elapsed = time.perf_counter() - t0\n",
        "  print(f\"\\n{count} downloads in {elapsed:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n"
      ],
      "metadata": {
        "id": "A9JAwPWQ-WsZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuEwg8zw8kL4",
        "outputId": "18a17f53-2bcf-4526-e112-c139a0010934"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BD BR CD CN DE EG ET FR ID IN IR KR MX NG PH PK RU TR US VN \n",
            "20 downloads in 6.43s\n"
          ]
        }
      ],
      "source": [
        "!python flags.py"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Downloading with concurrent.futures"
      ],
      "metadata": {
        "id": "NZENI7MNBVjg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Main Features: `ThreadPoolExecutor` and `ProcessPoolExectuor` classes, which implement an API to submit cllables for execution in different threads or processes. The classes transparently manage a pool of worker threads or processes, and queues to distribute jobs and collect results."
      ],
      "metadata": {
        "id": "GDYjWHmrBYPQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags_threadpool.py\n",
        "from concurrent import futures\n",
        "\n",
        "from flags import save_flag, get_flag, main\n",
        "\n",
        "def download_one(cc: str):\n",
        "  image = get_flag(cc)\n",
        "  save_flag(image, f'{cc}.gif')\n",
        "  print(cc, end=\" \", flush=True)\n",
        "  return cc\n",
        "\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "  # instantiate the thread pool executor as a context manager\n",
        "  # exectuor.__exit__ will call executor.shutdown(wait=True) which will block until all threads are done\n",
        "  with futures.ThreadPoolExecutor() as executor:\n",
        "    res = executor.map(download_one, sorted(cc_list))\n",
        "\n",
        "  return len(list(res))\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n",
        "\n"
      ],
      "metadata": {
        "id": "IOEmKlPTA70y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python flags_threadpool.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yt_hc9R0C5HQ",
        "outputId": "dd97d199-65b7-49c2-9c80-3dd6e1274df4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BD CN DE BR EG CD ET ID FR KR IN IR MX NG PH RU PK TR US VN \n",
            "20 downloads in 1.29s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "os.cpu_count() + 4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DxdiwF5EC_xi",
        "outputId": "d8bb7d9d-122a-429e-91df-bb50d351208e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Where are teh Futures?\n",
        "\n",
        "Futures are core components of `concurrent.futures` and of `asyncio` but as users of these libraries we sometimes don't see them.\n",
        "\n",
        "There are two classes naemd `Future` in the standard library: `concurrent.futures.Future` and `asyncio.Future`. They serve the same purpose: an instance of either `Future` class represents a deferred computation that may or may not have completed.\n",
        "\n",
        "Futures encapsulate pending operations so that we can put them in queues, check whether they are done, and retrieve results when they become available.\n",
        "\n",
        "We should not create them: they are meant to be instantiated exclusively by the concurrency framework, be it `concurrent.futures` or `asyncio`. Why? a `Future` represents something that will eventually run, therefore it must be scheduled to run, and that's the job of the framework.\n",
        "\n",
        "Application code is not supposed to change the state of the a future: the concurrency framework changes the state of a future when the computation it represents is done, and we can't control when that happens.\n",
        "\n",
        "Both types of `Future` have a `.done()` method that is nonblocking and returns a Boolean that tells you whether the callable wrapped by that future has executed or not. However, instaed of repeatedly asking whether a future is done, client code usually asks to be notified. That's why both `Future` classes have an `.add_done_callback()` method.\n",
        "\n",
        "There is also a `.result()` method, which works the same in both classes when the future is done: it returns the result of the callable, or re-raises whatever exception might have been thrown when the callable was executed. However, when the future is not done, the behavior of the `result` method is very different."
      ],
      "metadata": {
        "id": "gmb6b1Bne70O"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# flags_threadpool_futures.py\n",
        "from concurrent import futures\n",
        "\n",
        "from flags import save_flag, get_flag, main\n",
        "\n",
        "def download_one(cc: str):\n",
        "  image = get_flag(cc)\n",
        "  save_flag(image, f'{cc}.gif')\n",
        "  print(cc, end=\" \", flush=True)\n",
        "  return cc\n",
        "\n",
        "def download_many(cc_list: list[str]) -> int:\n",
        "\n",
        "  cc_list = cc_list[:5] # just for this demonstration\n",
        "  # instantiate the thread pool executor as a context manager\n",
        "  # exectuor.__exit__ will call executor.shutdown(wait=True) which will block until all threads are done\n",
        "  with futures.ThreadPoolExecutor(max_workers=3) as executor: # max_workers=3 to see pending futures in the output\n",
        "    to_do: list[futures.Future] = []\n",
        "    for cc in sorted(cc_list):\n",
        "      future = executor.submit(download_one, cc)\n",
        "      to_do.append(future)\n",
        "      print(f\"Scheduled for {cc}: {future}\")\n",
        "\n",
        "    for count, future in enumerate(futures.as_completed(to_do), 1):\n",
        "      res: str = future.result()\n",
        "      print(f\"{future} result: {res!r}\")\n",
        "\n",
        "  return count\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main(download_many)\n",
        "\n"
      ],
      "metadata": {
        "id": "4jSjKgBPDQ9g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "`concurrent.futures.as_completed` function takes an iterable of futures and returns an iterator that yields futures as they are done.\n",
        "\n",
        "The higher-level `executor.map` is replaced by two `for` loops: one to create and schedule the futures, the other to retrieve their results. While we are at it, we'll add a few `print` calls to display each future before and after it's done."
      ],
      "metadata": {
        "id": "ZpLBSvAph8-9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!python flags_threadpool_futures.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UPxVT7umh8a7",
        "outputId": "50bfe5a1-335b-46ed-cf73-e346b0488162"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Scheduled for BR: <Future at 0x799001ff6260 state=running>\n",
            "Scheduled for CN: <Future at 0x799001d70c10 state=running>\n",
            "Scheduled for ID: <Future at 0x799001d71480 state=running>\n",
            "Scheduled for IN: <Future at 0x799001d71d80 state=pending>\n",
            "Scheduled for US: <Future at 0x799001d71db0 state=pending>\n",
            "CN <Future at 0x799001d70c10 state=finished returned str> result: 'CN'\n",
            "ID <Future at 0x799001d71480 state=finished returned str> result: 'ID'\n",
            "BR <Future at 0x799001ff6260 state=finished returned str> result: 'BR'\n",
            "IN <Future at 0x799001d71d80 state=finished returned str> result: 'IN'\n",
            "US <Future at 0x799001d71db0 state=finished returned str> result: 'US'\n",
            "\n",
            "5 downloads in 0.35s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, let's take a brief look at a simple way to work around the GIL for CPU-bound jobs using `concurrent.futures`.\n",
        "\n",
        "## Launching Processes with concurrent.futures\n",
        "\n",
        "The real value of `ProcessPoolExecutor` is in CPU-intensive jobs."
      ],
      "metadata": {
        "id": "Tx7CvjtYjbdv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# proc_pool.py\n",
        "\n",
        "import sys\n",
        "from concurrent import futures # hides multiprocessing / SimpleQueue / etc\n",
        "from time import perf_counter\n",
        "from typing import NamedTuple\n",
        "\n",
        "from primes import is_prime, NUMBERS\n",
        "\n",
        "class PrimeResult(NamedTuple):\n",
        "  n: int\n",
        "  flag: bool\n",
        "  elapsed: float\n",
        "\n",
        "def check(n: int) -> PrimeResult:\n",
        "  t0 = perf_counter()\n",
        "  res = is_prime(n)\n",
        "  return PrimeResult(n, res, perf_counter() - t0)\n",
        "\n",
        "def main() -> None:\n",
        "  if len(sys.argv) < 2:\n",
        "    workers = None\n",
        "  else:\n",
        "    workers = int(sys.argv[1])\n",
        "\n",
        "  executor = futures.ProcessPoolExecutor(workers)\n",
        "  actual_workers = executor._max_workers # type: ignore\n",
        "\n",
        "  print(f\"Checking {len(NUMBERS)} numbers with {actual_workers} processes:\")\n",
        "\n",
        "  t0 = perf_counter()\n",
        "\n",
        "  numbers = sorted(NUMBERS, reverse=True)\n",
        "  with executor:\n",
        "    # executor.map() returns the result in the same order as the numbers are given\n",
        "    for n, prime, elapsed in executor.map(check, numbers):\n",
        "      label = 'P' if prime else ' '\n",
        "      print(f\"{n: 16}   {label} {elapsed:9.6f}s\")\n",
        "\n",
        "  time = perf_counter() - t0\n",
        "  print(f\"Total time: {time:.2f}s\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "  main()"
      ],
      "metadata": {
        "id": "g4JXyJboiyXL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!python proc_pool.py"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ejfDcgP4lhrD",
        "outputId": "fce99851-5c98-4933-c9d3-bc6e5dcee58d"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Checking 20 numbers with 2 processes:\n",
            " 9999999999999999      0.000036s\n",
            " 9999999999999917   P 15.200927s\n",
            " 7777777777777777      0.000005s\n",
            " 7777777777777753   P 13.473852s\n",
            " 7777777536340681     13.214291s\n",
            " 6666667141414921     12.325249s\n",
            " 6666666666666719   P 12.355056s\n",
            " 6666666666666666      0.000002s\n",
            " 5555555555555555      0.000009s\n",
            " 5555555555555503   P 11.451030s\n",
            " 5555553133149889     12.853707s\n",
            " 4444444488888889     11.632231s\n",
            " 4444444444444444      0.000002s\n",
            " 4444444444444423   P  9.667734s\n",
            " 3333335652092209      8.738373s\n",
            " 3333333333333333      0.000010s\n",
            " 3333333333333301   P  6.512187s\n",
            " 299593572317531   P  2.902751s\n",
            " 142702110479723   P  1.590411s\n",
            "               2   P  0.000002s\n",
            "Total time: 66.87s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "k5SCE4nFligQ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}